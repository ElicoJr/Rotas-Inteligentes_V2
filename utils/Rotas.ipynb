{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f17f4e4a",
   "metadata": {},
   "source": [
    "### imports e configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc24b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import LineString, Point\n",
    "\n",
    "# Configurações: endpoints locais\n",
    "VROOM_BASES = [\n",
    "    \"http://localhost:3000/solve\",   # endpoint comum (tentativa)\n",
    "    \"http://localhost:3000/route\",\n",
    "    \"http://localhost:3000/solve-route\",\n",
    "    \"http://localhost:3000/routes\",\n",
    "    \"http://localhost:3000\"           # fallback; we'll try POSTs to endpoints in try_vroom_solve\n",
    "]\n",
    "OSRM_TABLE_BASE = \"http://localhost:5000/table/v1/driving\"  # OSRM table service\n",
    "DEPOT = (-8.738553348981176, -63.88547754489104)  # (lat, lon)\n",
    "\n",
    "# Seeds\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "def parse_dt(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    if isinstance(x, datetime):\n",
    "        return x\n",
    "    try:\n",
    "        return pd.to_datetime(x).to_pydatetime()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def secs(td: timedelta):\n",
    "    return td.total_seconds()\n",
    "\n",
    "def haversine_m(lat1, lon1, lat2, lon2):\n",
    "    # meters\n",
    "    R = 6371000\n",
    "    phi1 = math.radians(lat1); phi2 = math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlambda = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2\n",
    "    return 2*R*math.asin(math.sqrt(a))\n",
    "def try_vroom_solve(payload: dict, timeout=30) -> dict:\n",
    "    \"\"\"\n",
    "    Tenta enviar payload para vários endpoints VROOM locais plausíveis até obter uma resposta válida.\n",
    "    Retorna o JSON da resposta ou lança erro com último status.\n",
    "    \"\"\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    last_exc = None\n",
    "    for url in VROOM_BASES:\n",
    "        try:\n",
    "            resp = requests.post(url, json=payload, headers=headers, timeout=timeout)\n",
    "            if resp.status_code == 200:\n",
    "                return resp.json()\n",
    "            # alguns VROOMs respondem 201 or 202; accept 200-299\n",
    "            if 200 <= resp.status_code < 300:\n",
    "                return resp.json()\n",
    "            # otherwise continue trying other endpoints\n",
    "            last_exc = Exception(f\"VROOM {url} status {resp.status_code}: {resp.text[:200]}\")\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "    raise last_exc\n",
    "def osrm_table(coords: List[Tuple[float,float]], annotations: str=\"duration,distance\", sources=None, destinations=None, timeout=30) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    coords: list of (lat, lon)\n",
    "    returns (durations_matrix_seconds, distances_matrix_meters) as numpy arrays\n",
    "    \"\"\"\n",
    "    # OSRM expects lon,lat list in path\n",
    "    coord_str = \";\".join([f\"{lon},{lat}\" for lat,lon in coords])\n",
    "    params = {\"annotations\": annotations}\n",
    "    if sources is not None:\n",
    "        params[\"sources\"] = \";\".join(map(str,sources))\n",
    "    if destinations is not None:\n",
    "        params[\"destinations\"] = \";\".join(map(str,destinations))\n",
    "    url = f\"{OSRM_TABLE_BASE}/{coord_str}\"\n",
    "    resp = requests.get(url, params=params, timeout=timeout)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    durations = np.array(data.get(\"durations\", []), dtype=float)\n",
    "    distances = np.array(data.get(\"distances\", []), dtype=float)\n",
    "    return durations, distances\n",
    "def build_jobs_from_dfs(df_tecnicos: pd.DataFrame, df_comerciais: pd.DataFrame) -> List[Dict]:\n",
    "    jobs = []\n",
    "    idx = 0\n",
    "    # técnicos\n",
    "    for _, r in df_tecnicos.iterrows():\n",
    "        tw_start = parse_dt(r.get(\"DH_INICIO\") or r.get(\"DH_ALOCACAO\") or r.get(\"DH_CHEGADA\"))\n",
    "        tw_end   = parse_dt(r.get(\"DH_FINAL\"))\n",
    "        te = r.get(\"TE\")  # assume minutes\n",
    "        try:\n",
    "            te_min = float(te)\n",
    "        except:\n",
    "            te_min = 30.0\n",
    "        jobs.append({\n",
    "            \"id\": idx,\n",
    "            \"NUMOS\": r.get(\"NUMOS\"),\n",
    "            \"tipo\": \"tecnico\",\n",
    "            \"coord\": (float(r['LATITUDE']), float(r['LONGITUDE'])),\n",
    "            \"tw_start\": tw_start,\n",
    "            \"tw_end\": tw_end,\n",
    "            \"TE_min\": te_min,\n",
    "            \"row\": r\n",
    "        })\n",
    "        idx += 1\n",
    "    # comerciais\n",
    "    for _, r in df_comerciais.iterrows():\n",
    "        tw_start = parse_dt(r.get(\"DATAINITRAB\") or r.get(\"DATA_SOL\"))\n",
    "        tw_end   = parse_dt(r.get(\"DATATERTRAB\") or r.get(\"DATA_VENC\"))\n",
    "        te = r.get(\"TE\")\n",
    "        try:\n",
    "            te_min = float(te)\n",
    "        except:\n",
    "            te_min = 30.0\n",
    "        jobs.append({\n",
    "            \"id\": idx,\n",
    "            \"NUMOS\": r.get(\"NUMOS\"),\n",
    "            \"tipo\": \"comercial\",\n",
    "            \"codserv\": r.get(\"CODSERV\"),\n",
    "            \"coord\": (float(r['LATITUDE']), float(r['LONGITUDE'])),\n",
    "            \"tw_start\": tw_start,\n",
    "            \"tw_end\": tw_end,\n",
    "            \"TE_min\": te_min,\n",
    "            \"row\": r\n",
    "        })\n",
    "        idx += 1\n",
    "    return jobs\n",
    "\n",
    "def build_vehicles_from_eq(df_equipes: pd.DataFrame) -> List[Dict]:\n",
    "    vehicles = []\n",
    "    for i, r in df_equipes.iterrows():\n",
    "        shift_start = parse_dt(r.get(\"dthaps_ini\") or r.get(\"data_inicio_turno\"))\n",
    "        shift_end   = parse_dt(r.get(\"dthaps_fim_ajustado\") or r.get(\"data_fim_turno\") or r.get(\"dthaps_fim\"))\n",
    "        b_ini = parse_dt(r.get(\"dthpausa_ini\"))\n",
    "        b_fim = parse_dt(r.get(\"dthpausa_fim\"))\n",
    "        vehicles.append({\n",
    "            \"id\": int(i),\n",
    "            \"equipe\": r.get(\"equipe\") or f\"EQ{i}\",\n",
    "            \"shift_start\": shift_start,\n",
    "            \"shift_end\": shift_end,\n",
    "            \"breaks\": [(b_ini, b_fim)] if (b_ini and b_fim) else [],\n",
    "            \"start_coord\": DEPOT,\n",
    "            \"end_coord\": DEPOT,\n",
    "            \"row\": r\n",
    "        })\n",
    "    return vehicles\n",
    "# Observa: não trabalhar em horário de pausa; comerciais 739/741 entre 08-18; não atender job com DATA_SOL/DH_INICIO > shift_end (futuro)\n",
    "def simulate_route_timeline(route_job_ids: List[int], jobs: List[Dict], vehicle: Dict, durations_matrix: np.ndarray, idx_map: Dict[int,int]) -> Tuple[bool, Dict]:\n",
    "    \"\"\"\n",
    "    Simula execução sequencial da rota (job order given).\n",
    "    idx_map: job_id -> position in durations_matrix (0 is depot)\n",
    "    Returns (feasible, details) where details includes arrival, start, finish times for each job and totals.\n",
    "    \"\"\"\n",
    "    cur_time = vehicle['shift_start']\n",
    "    if cur_time is None or vehicle['shift_end'] is None:\n",
    "        return False, {\"reason\":\"no_shift_times\"}\n",
    "    prev = 0  # depot index in matrix\n",
    "    schedule = []\n",
    "    total_travel = 0.0\n",
    "    total_service = 0.0\n",
    "    for jid in route_job_ids:\n",
    "        pos = idx_map[jid]\n",
    "        travel_sec = durations_matrix[prev, pos]\n",
    "        arrival = cur_time + timedelta(seconds=float(travel_sec))\n",
    "        job = jobs[jid]\n",
    "        # rule: no future job beyond shift_end\n",
    "        if job['tw_start'] and job['tw_start'] > vehicle['shift_end']:\n",
    "            return False, {\"reason\":\"job_in_future\", \"job\": job['NUMOS']}\n",
    "        # if arrival before tw_start, wait\n",
    "        if job['tw_start'] and arrival < job['tw_start']:\n",
    "            arrival = job['tw_start']\n",
    "        # comercial 739/741 only 8-18\n",
    "        if job['tipo'] == 'comercial':\n",
    "            cod = job.get('codserv')\n",
    "            if cod in [739,741] or cod == '739' or cod == '741':\n",
    "                if not (8 <= arrival.hour < 18):\n",
    "                    return False, {\"reason\":\"comercial_noite\", \"job\":job['NUMOS']}\n",
    "        # check break overlap\n",
    "        for b in vehicle['breaks']:\n",
    "            if b[0] and b[1]:\n",
    "                start_service = arrival\n",
    "                finish_service = arrival + timedelta(minutes=job['TE_min'])\n",
    "                if (start_service < b[1]) and (finish_service > b[0]):\n",
    "                    return False, {\"reason\":\"overlaps_break\", \"job\": job['NUMOS']}\n",
    "        # check tw_end\n",
    "        if job['tw_end'] and arrival > job['tw_end']:\n",
    "            return False, {\"reason\":\"tw_end_violation\", \"job\": job['NUMOS']}\n",
    "        finish = arrival + timedelta(minutes=job['TE_min'])\n",
    "        # can return to depot before shift_end? we check after finishing last job; but to be safe ensure that after finishing the job and going back to depot we are <= shift_end\n",
    "        ret_sec = durations_matrix[pos, 0]\n",
    "        back_arrival = finish + timedelta(seconds=float(ret_sec))\n",
    "        if back_arrival > vehicle['shift_end']:\n",
    "            return False, {\"reason\":\"cannot_return_before_shift_end\", \"job\": job['NUMOS']}\n",
    "        # append schedule item\n",
    "        schedule.append({\n",
    "            \"job_id\": jid,\n",
    "            \"numos\": job['NUMOS'],\n",
    "            \"arrival\": arrival,\n",
    "            \"start\": arrival,\n",
    "            \"finish\": finish\n",
    "        })\n",
    "        total_travel += float(travel_sec)\n",
    "        total_service += job['TE_min']*60.0\n",
    "        cur_time = finish\n",
    "        prev = pos\n",
    "    # final return\n",
    "    total_travel += float(durations_matrix[prev,0])\n",
    "    # ok\n",
    "    details = {\n",
    "        \"schedule\": schedule,\n",
    "        \"total_travel_sec\": total_travel,\n",
    "        \"total_service_sec\": total_service,\n",
    "        \"finish_time\": schedule[-1]['finish'] if schedule else vehicle['shift_start']\n",
    "    }\n",
    "    return True, details\n",
    "def compute_penalties_for_route(route_job_ids: List[int], jobs: List[Dict], details: Dict) -> float:\n",
    "    \"\"\"\n",
    "    Returns penalty (unit: hours-equivalent multiplied into cost later).\n",
    "    - técnico: (duração_da_interrupção * (EUSD/730) * 34)\n",
    "      duração_da_interrupção: if DH_INICIO & DH_FINAL present -> use that duration_hours; else use TE_min/60\n",
    "    - comercial: 120 + 34 * EUSD * log(prazo_verificado / prazo_regulatorio)\n",
    "      prazo_verificado: (DATA_VENC - arrival).days (in days, min 1)\n",
    "      prazo_regulatorio: use 7 days default (adjust if you have regulatory value)\n",
    "    \"\"\"\n",
    "    penalty = 0.0\n",
    "    for item in details.get(\"schedule\", []):\n",
    "        job = jobs[item['job_id']]\n",
    "        if job['tipo']=='tecnico':\n",
    "            row = job['row']\n",
    "            dh_ini = parse_dt(row.get(\"DH_INICIO\"))\n",
    "            dh_fin = parse_dt(row.get(\"DH_FINAL\"))\n",
    "            if dh_ini and dh_fin:\n",
    "                dur_hours = max(0.0, (dh_fin - dh_ini).total_seconds()/3600.0)\n",
    "            else:\n",
    "                dur_hours = job['TE_min']/60.0\n",
    "            eusd = row.get(\"EUSD\") or row.get(\"EUSD_FIO_B\") or 1.0\n",
    "            try:\n",
    "                eusd_v = float(eusd)\n",
    "            except:\n",
    "                eusd_v = 1.0\n",
    "            penalty += dur_hours * (eusd_v/730.0) * 34.0\n",
    "        else:  # comercial\n",
    "            row = job['row']\n",
    "            eusd = row.get(\"EUSD\") or row.get(\"EUSD_FIO_B\") or 1.0\n",
    "            try:\n",
    "                eusd_v = float(eusd)\n",
    "            except:\n",
    "                eusd_v = 1.0\n",
    "            venc = job.get(\"vencimento\") or parse_dt(row.get(\"DATA_VENC\"))\n",
    "            arrival = item['arrival']\n",
    "            if venc:\n",
    "                prazo_verificado = max(1.0, (venc - arrival).total_seconds()/(3600.0*24.0))\n",
    "                prazo_reg = 7.0\n",
    "                try:\n",
    "                    penalty += (235.97/2) + 15 * eusd_v * math.log(max(1.0, prazo_verificado/prazo_reg))\n",
    "                except:\n",
    "                    penalty += 120.0\n",
    "            else:\n",
    "                penalty += 120.0\n",
    "    return penalty\n",
    "# Representação: cromossomo = permutação dos job_ids com separators -1 per vehicle (end marker).\n",
    "def random_chromosome(n_jobs, n_veh):\n",
    "    \"\"\"\n",
    "    Retorna um cromossomo que representa uma atribuição de jobs para veículos.\n",
    "    Se n_jobs < n_veh, algumas rotas serão vazias, o que é permitido.\n",
    "    \"\"\"\n",
    "    # ordem aleatória dos jobs\n",
    "    perm = list(range(n_jobs))\n",
    "    random.shuffle(perm)\n",
    "\n",
    "    # número de cortes real possível\n",
    "    max_cuts = max(0, min(n_veh-1, n_jobs-1))\n",
    "\n",
    "    if max_cuts > 0:\n",
    "        cuts = sorted(random.sample(range(1, n_jobs), max_cuts))\n",
    "    else:\n",
    "        cuts = []\n",
    "\n",
    "    chrom = []\n",
    "    last = 0\n",
    "    for c in cuts:\n",
    "        chrom.append(perm[last:c])\n",
    "        last = c\n",
    "    chrom.append(perm[last:])\n",
    "\n",
    "    # se faltarem equipes, preenche com rotas vazias\n",
    "    while len(chrom) < n_veh:\n",
    "        chrom.append([])\n",
    "\n",
    "    return chrom\n",
    "\n",
    "def decode_chromosome(chrom: List[int], n_veh: int) -> Dict[int, List[int]]:\n",
    "    routes = {}\n",
    "    vid = 0; cur = []\n",
    "    for g in chrom:\n",
    "        if g == -1:\n",
    "            routes[vid] = cur.copy()\n",
    "            cur = []\n",
    "            vid += 1\n",
    "            if vid>=n_veh:\n",
    "                break\n",
    "        else:\n",
    "            cur.append(g)\n",
    "    # pad if missing\n",
    "    for v in range(n_veh):\n",
    "        routes.setdefault(v, [])\n",
    "    return routes\n",
    "\n",
    "def fitness_of_chrom(chrom: List[int], jobs: List[Dict], vehicles: List[Dict], osrm_cache_coords: List[Tuple[float,float]]):\n",
    "    \"\"\"\n",
    "    For each vehicle route (set of jobs; order not considered here), call VROOM to order them and then OSRM table to simulate timeline.\n",
    "    We'll compute total cost = sum(total_travel_sec + penalty*3600).\n",
    "    This is expensive (calls VROOM+OSRM), so: GA size must be moderate.\n",
    "    \"\"\"\n",
    "    n_veh = len(vehicles)\n",
    "    routes = decode_chromosome(chrom, n_veh)\n",
    "    total_cost = 0.0\n",
    "    # Pre-build mapping job_id -> coords\n",
    "    for vid, job_list in routes.items():\n",
    "        # Build VROOM payload for this single vehicle (vehicle info + jobs with time windows)\n",
    "        if not job_list:\n",
    "            continue\n",
    "        veh = vehicles[vid]\n",
    "        vroom_payload = {\"vehicles\": [], \"jobs\": []}\n",
    "        vroom_vehicle = {\n",
    "            \"id\": 1,\n",
    "            \"start\": [veh['start_coord'][1], veh['start_coord'][0]],  # [lon,lat]\n",
    "            \"end\": [veh['end_coord'][1], veh['end_coord'][0]],\n",
    "            \"time_window\": [\n",
    "                int(veh['shift_start'].timestamp()),\n",
    "                int(veh['shift_end'].timestamp())\n",
    "            ]\n",
    "        }\n",
    "        vroom_payload['vehicles'].append(vroom_vehicle)\n",
    "        # jobs as per assigned set — VROOM will optimize order\n",
    "        for j in job_list:\n",
    "            job = jobs[j]\n",
    "            tw = None\n",
    "            if job['tw_start'] and job['tw_end']:\n",
    "                tw = [int(job['tw_start'].timestamp()), int(job['tw_end'].timestamp())]\n",
    "            vroom_job = {\n",
    "                \"id\": int(job['id']),\n",
    "                \"location\": [job['coord'][1], job['coord'][0]],\n",
    "                \"service\": int(job['TE_min']*60),\n",
    "            }\n",
    "            if tw:\n",
    "                vroom_job[\"time_window\"] = tw\n",
    "            vroom_payload['jobs'].append(vroom_job)\n",
    "        # call VROOM to get route order\n",
    "        try:\n",
    "            vroom_resp = try_vroom_solve(vroom_payload, timeout=20)\n",
    "        except Exception as e:\n",
    "            # If VROOM fails, assign a high cost to this partition\n",
    "            return 1e18\n",
    "        # Parse VROOM response to get ordered list of job ids for this vehicle.\n",
    "        # VROOM responses vary by version; try common patterns:\n",
    "        ordered_job_ids = []\n",
    "        # Pattern 1: vroom_resp has 'routes' list with 'steps' or 'jobs'\n",
    "        if isinstance(vroom_resp, dict):\n",
    "            # vroom standard sometimes returns 'routes' or 'solution' -> 'routes'\n",
    "            if 'routes' in vroom_resp:\n",
    "                # take first route\n",
    "                route = vroom_resp['routes'][0]\n",
    "                # route may contain 'steps' with 'job' or 'activities'\n",
    "                # vroom also provides 'jobs' ordered in some responses\n",
    "                if 'steps' in route:\n",
    "                    for s in route['steps']:\n",
    "                        if s.get('type')=='job':\n",
    "                            ordered_job_ids.append(int(s.get('ref') or s.get('job')))\n",
    "                elif 'jobs' in route:\n",
    "                    ordered_job_ids = [int(x) for x in route['jobs']]\n",
    "                elif 'activities' in route:\n",
    "                    for act in route['activities']:\n",
    "                        if act.get('type')=='job' and 'job' in act:\n",
    "                            ordered_job_ids.append(int(act['job']))\n",
    "            # fallback if vroom_resp returns 'solution' object\n",
    "            if not ordered_job_ids and 'solution' in vroom_resp and 'routes' in vroom_resp['solution']:\n",
    "                route = vroom_resp['solution']['routes'][0]\n",
    "                if 'steps' in route:\n",
    "                    for s in route['steps']:\n",
    "                        if s.get('type')=='job':\n",
    "                            ordered_job_ids.append(int(s.get('ref') or s.get('job')))\n",
    "        # If still empty, attempt to parse common top-level keys\n",
    "        if not ordered_job_ids:\n",
    "            # try if response contains 'routes' as list of ints\n",
    "            try:\n",
    "                if 'route' in vroom_resp and isinstance(vroom_resp['route'], dict) and 'jobs' in vroom_resp['route']:\n",
    "                    ordered_job_ids = [int(x) for x in vroom_resp['route']['jobs']]\n",
    "            except:\n",
    "                pass\n",
    "        if not ordered_job_ids:\n",
    "            # As final fallback, use the input job_list order\n",
    "            ordered_job_ids = job_list.copy()\n",
    "\n",
    "        # Now call OSRM table for coords in order: depot + ordered jobs\n",
    "        coords_for_osrm = [DEPOT] + [jobs[j]['coord'] for j in ordered_job_ids]\n",
    "        try:\n",
    "            durations, distances = osrm_table(coords_for_osrm)\n",
    "        except Exception as e:\n",
    "            return 1e18\n",
    "\n",
    "        # Build idx_map: job index -> position in durations (0 is depot, jobs start at 1)\n",
    "        idx_map = {}\n",
    "        for pos, j in enumerate(ordered_job_ids, start=1):\n",
    "            # find job's global id index (it is j)\n",
    "            idx_map[j] = pos\n",
    "\n",
    "        # Simulate timeline based on OSRM durations and the VROOM order\n",
    "        feasible, sim_details = simulate_route_timeline(ordered_job_ids, jobs, veh, durations, idx_map)\n",
    "        if not feasible:\n",
    "            # infeasible partition -> large cost\n",
    "            return 1e17\n",
    "        # compute penalty\n",
    "        pen = compute_penalties_for_route(ordered_job_ids, jobs, sim_details)\n",
    "        # cost: travel sec + penalty*3600 (scale penalty to seconds)\n",
    "        cost_for_vehicle = sim_details['total_travel_sec'] + pen * 3600.0\n",
    "        total_cost += cost_for_vehicle\n",
    "    return total_cost\n",
    "\n",
    "# Célula 10: GA main loop (moderado) + SA refinement on best individuals\n",
    "def run_ga_assignment(jobs: List[Dict], vehicles: List[Dict], generations=40, pop_size=30):\n",
    "    n_jobs = len(jobs); n_veh = len(vehicles)\n",
    "    # precompute coords list to speed OSRM calls? we'll call OSRM per evaluation so caching would be complex; keep it simple\n",
    "    pop = [random_chromosome(n_jobs, n_veh) for _ in range(pop_size)]\n",
    "    fitness = [None]*pop_size\n",
    "    for i,chrom in enumerate(pop):\n",
    "        fitness[i] = fitness_of_chrom(chrom, jobs, vehicles, None)\n",
    "    for gen in range(generations):\n",
    "        # selection: tournament\n",
    "        newpop = []\n",
    "        for _ in range(pop_size//2):\n",
    "            # select parents\n",
    "            p1 = min(random.sample(pop, k=3), key=lambda c: fitness_of_chrom(c, jobs, vehicles, None))\n",
    "            p2 = min(random.sample(pop, k=3), key=lambda c: fitness_of_chrom(c, jobs, vehicles, None))\n",
    "            # crossover\n",
    "            a,b = one_point_crossover_varlen(p1,p2)\n",
    "            a = mutate_swap(a, 0.12)\n",
    "            b = mutate_swap(b, 0.12)\n",
    "            newpop.extend([a,b])\n",
    "        # evaluate newpop\n",
    "        pop = newpop\n",
    "        fitness = [fitness_of_chrom(c, jobs, vehicles, None) for c in pop]\n",
    "        # keep best printed\n",
    "        best_idx = int(np.argmin(fitness))\n",
    "        print(f\"GA gen {gen} best {fitness[best_idx]:.2f}\")\n",
    "    best_chrom = pop[int(np.argmin(fitness))]\n",
    "    best_routes = decode_chromosome(best_chrom, len(vehicles))\n",
    "    return best_routes, best_chrom\n",
    "\n",
    "# helpers: crossover / mutate\n",
    "def one_point_crossover_varlen(a,b):\n",
    "    if len(a)!=len(b):\n",
    "        # pad shorter with random permutation to equalize length (rare)\n",
    "        n = max(len(a), len(b))\n",
    "        a2 = a[:] + random.sample([x for x in range(n) if x not in a], k=max(0,n-len(a)))\n",
    "        b2 = b[:] + random.sample([x for x in range(n) if x not in b], k=max(0,n-len(b)))\n",
    "        a,b = a2,b2\n",
    "    pt = random.randint(1, len(a)-2)\n",
    "    ca = a[:pt] + [x for x in b[pt:] if x not in a[:pt]]\n",
    "    cb = b[:pt] + [x for x in a[pt:] if x not in b[:pt]]\n",
    "    if ca[-1]!=-1: ca.append(-1)\n",
    "    if cb[-1]!=-1: cb.append(-1)\n",
    "    return ca, cb\n",
    "\n",
    "def mutate_swap(chrom, rate=0.15):\n",
    "    idxs = [i for i,g in enumerate(chrom) if g!=-1]\n",
    "    for i in idxs:\n",
    "        if random.random()<rate:\n",
    "            j=random.choice(idxs); chrom[i],chrom[j]=chrom[j],chrom[i]\n",
    "    return chrom\n",
    "\n",
    "# Célula 11: função principal que roda dia a dia (P1), obrigando atribuição de todos os jobs.\n",
    "def run_day(df_equipes: pd.DataFrame, df_tecnicos: pd.DataFrame, df_comerciais: pd.DataFrame, day: datetime.date, use_vroom=True):\n",
    "    \"\"\"\n",
    "    - Filtra jobs whose date (DH_INICIO or DATA_SOL) falls on 'day'\n",
    "    - Builds jobs and vehicles for that day\n",
    "    - Runs GA to partition jobs among vehicles (assignment)\n",
    "    - For each vehicle, calls VROOM to get order and OSRM table to compute times and simulate DH_FINAL\n",
    "    - Returns structured summary including simulated DH_FINAL values\n",
    "    \"\"\"\n",
    "    # filter by day\n",
    "    def job_on_day(row, datecolnames):\n",
    "        for c in datecolnames:\n",
    "            v = parse_dt(row.get(c))\n",
    "            if v and v.date() == day:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    df_t = df_tecnicos.copy()\n",
    "    df_c = df_comerciais.copy()\n",
    "    df_t = df_t[df_t.apply(lambda r: job_on_day(r, [\"DH_INICIO\",\"DH_ALOCACAO\",\"DH_CHEGADA\"]), axis=1)].reset_index(drop=True)\n",
    "    df_c = df_c[df_c.apply(lambda r: job_on_day(r, [\"DATA_SOL\",\"DATAINITRAB\"]), axis=1)].reset_index(drop=True)\n",
    "\n",
    "    jobs = build_jobs_from_dfs(df_t, df_c)\n",
    "    vehicles = build_vehicles_from_eq(df_equipes)\n",
    "\n",
    "    if not jobs:\n",
    "        print(\"Nenhum job para este dia:\", day)\n",
    "        return {}\n",
    "\n",
    "    # Run GA assignment (note: expensive; adjust generations/pop_size as needed)\n",
    "    print(f\"Rodando GA de atribuição para {len(jobs)} jobs e {len(vehicles)} veículos...\")\n",
    "    best_routes, best_chrom = run_ga_assignment(jobs, vehicles, generations=20, pop_size=20)\n",
    "\n",
    "    # For each vehicle, get VROOM order and then OSRM times to simulate final times\n",
    "    summary = {\"day\": str(day), \"vehicles\": []}\n",
    "    for vid, job_list in best_routes.items():\n",
    "        veh = vehicles[vid]\n",
    "        if not job_list:\n",
    "            summary[\"vehicles\"].append({\"vehicle_id\": vid, \"equipe\": veh['equipe'], \"route\": [], \"details\": {}})\n",
    "            continue\n",
    "        # build VROOM payload (vehicle + jobs)\n",
    "        vroom_payload = {\"vehicles\": [], \"jobs\": []}\n",
    "        vroom_vehicle = {\n",
    "            \"id\": 1,\n",
    "            \"start\": [veh['start_coord'][1], veh['start_coord'][0]],\n",
    "            \"end\": [veh['end_coord'][1], veh['end_coord'][0]],\n",
    "            \"time_window\": [\n",
    "                int(veh['shift_start'].timestamp()),\n",
    "                int(veh['shift_end'].timestamp())\n",
    "            ]\n",
    "        }\n",
    "        vroom_payload['vehicles'].append(vroom_vehicle)\n",
    "        for j in job_list:\n",
    "            job = jobs[j]\n",
    "            job_payload = {\n",
    "                \"id\": int(job['id']),\n",
    "                \"location\": [job['coord'][1], job['coord'][0]],\n",
    "                \"service\": int(job['TE_min']*60)\n",
    "            }\n",
    "            if job['tw_start'] and job['tw_end']:\n",
    "                job_payload[\"time_window\"] = [int(job['tw_start'].timestamp()), int(job['tw_end'].timestamp())]\n",
    "            vroom_payload['jobs'].append(job_payload)\n",
    "\n",
    "        # call VROOM to get order\n",
    "        if use_vroom:\n",
    "            try:\n",
    "                vroom_resp = try_vroom_solve(vroom_payload, timeout=20)\n",
    "            except Exception as e:\n",
    "                print(\"VROOM call failed:\", e)\n",
    "                # fallback to original ordering\n",
    "                ordered_job_ids = job_list.copy()\n",
    "            else:\n",
    "                # parse vroom response to ordered ids (similar parsing as before)\n",
    "                ordered_job_ids = []\n",
    "                if 'routes' in vroom_resp:\n",
    "                    route = vroom_resp['routes'][0]\n",
    "                    if 'steps' in route:\n",
    "                        for s in route['steps']:\n",
    "                            if s.get('type')=='job':\n",
    "                                ref = s.get('ref') or s.get('job') or s.get('id')\n",
    "                                if ref is not None:\n",
    "                                    ordered_job_ids.append(int(ref))\n",
    "                    elif 'jobs' in route:\n",
    "                        ordered_job_ids = [int(x) for x in route['jobs']]\n",
    "                    elif 'activities' in route:\n",
    "                        for act in route['activities']:\n",
    "                            if act.get('type')=='job' and 'job' in act:\n",
    "                                ordered_job_ids.append(int(act['job']))\n",
    "                if not ordered_job_ids:\n",
    "                    ordered_job_ids = job_list.copy()\n",
    "        else:\n",
    "            ordered_job_ids = job_list.copy()\n",
    "\n",
    "        # OSRM table for depot + ordered jobs\n",
    "        coords_list = [DEPOT] + [jobs[j]['coord'] for j in ordered_job_ids]\n",
    "        durations, distances = osrm_table(coords_list)  # may raise if OSRM not reachable\n",
    "        # build index map\n",
    "        idx_map = {j: pos for pos,j in enumerate(ordered_job_ids, start=1)}\n",
    "\n",
    "        feasible, details = simulate_route_timeline(ordered_job_ids, jobs, veh, durations, idx_map)\n",
    "        if not feasible:\n",
    "            summary[\"vehicles\"].append({\"vehicle_id\": vid, \"equipe\": veh['equipe'], \"route\": ordered_job_ids, \"details\": {\"feasible\": False, \"reason\": details}})\n",
    "            continue\n",
    "        # compute penalties\n",
    "        pen = compute_penalties_for_route(ordered_job_ids, jobs, details)\n",
    "        # compute new DH_FINAL for each job as requested:\n",
    "        # \"final será dthaps_ini + tempo de chegada estimado + (TE em minutos)\"\n",
    "        # We'll compute an estimated DH_FINAL_sim for each job: vehicle.shift_start + travel_to_job + TE_min\n",
    "        est_new_final = []\n",
    "        # compute cumulative travel times along ordered list using durations matrix\n",
    "        cur_pos = 0\n",
    "        cur_time = veh['shift_start']\n",
    "        for jpos in ordered_job_ids:\n",
    "            pos = idx_map[jpos]\n",
    "            travel_sec = durations[cur_pos, pos]\n",
    "            arrival = cur_time + timedelta(seconds=float(travel_sec))\n",
    "            # DH_FINAL_sim = dthaps_ini + tempo_chegada_estimado + TE_min\n",
    "            DH_FINAL_sim = veh['shift_start'] + (arrival - veh['shift_start']) + timedelta(minutes=jobs[jpos]['TE_min'])\n",
    "            est_new_final.append({\"job_id\": jpos, \"NUMOS\": jobs[jpos]['NUMOS'], \"DH_FINAL_sim\": DH_FINAL_sim})\n",
    "            # update cur_time = finish\n",
    "            cur_time = arrival + timedelta(minutes=jobs[jpos]['TE_min'])\n",
    "            cur_pos = pos\n",
    "\n",
    "        vehicle_summary = {\n",
    "            \"vehicle_id\": vid,\n",
    "            \"equipe\": veh['equipe'],\n",
    "            \"ordered_job_ids\": ordered_job_ids,\n",
    "            \"osrm_total_travel_sec\": details['total_travel_sec'],\n",
    "            \"osrm_total_service_sec\": details['total_service_sec'],\n",
    "            \"penalty\": pen,\n",
    "            \"sim_details\": details,\n",
    "            \"DH_FINAL_sim_list\": est_new_final\n",
    "        }\n",
    "        summary[\"vehicles\"].append(vehicle_summary)\n",
    "    # Mark all jobs assigned check\n",
    "    assigned = []\n",
    "    for v in summary['vehicles']:\n",
    "        assigned.extend(v.get(\"ordered_job_ids\", []))\n",
    "    assigned_set = set(assigned)\n",
    "    all_jobs_set = set([j['id'] for j in jobs])\n",
    "    if assigned_set != all_jobs_set:\n",
    "        missing = all_jobs_set - assigned_set\n",
    "        print(\"Atenção: nem todos os jobs foram atribuídos! faltam:\", missing)\n",
    "    else:\n",
    "        print(\"Todos os jobs atribuídos com sucesso.\")\n",
    "    return summary\n",
    "\n",
    "# Célula 12: exemplo de execução\n",
    "# Substitua abaixo pelos seus DataFrames carregados\n",
    "# Exemplo: df_equipes = pd.read_csv(\"equipes.csv\", parse_dates=[...]); df_tecnicos = ...; df_comerciais = ...\n",
    "\n",
    "# Para demonstração, você deve carregar aqui seus dataframes reais. Exemplo:\n",
    "df_equipes = pd.read_parquet(\"data/Equipes.parquet\")\n",
    "df_tecnicos = pd.read_parquet(\"data/atendTec.parquet\")\n",
    "df_comerciais = pd.read_parquet(\"data/ServCom.parquet\")\n",
    "\n",
    "# Depois, rode por dia (exemplo: dias encontrados nas colunas DH_INICIO / DATA_SOL)\n",
    "# Aqui apenas um esqueleto para chamar run_day:\n",
    "\n",
    "day = datetime(2023, 5, 1).date()\n",
    "summary_day = run_day(df_equipes, df_tecnicos, df_comerciais, day, use_vroom=True)\n",
    "from pprint import pprint\n",
    "pprint(summary_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d25988",
   "metadata": {},
   "source": [
    "### utilitários de datas e distâncias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab57ab4b",
   "metadata": {},
   "source": [
    "### funções para tentar o endpoint VROOM (robustez)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ce806",
   "metadata": {},
   "source": [
    "### função para pedir matriz OSRM (table) para um conjunto de coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950ec97f",
   "metadata": {},
   "source": [
    "### Build jobs/vehicles from seus DataFrames (assumindo nomes das colunas que você passou)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4180b4",
   "metadata": {},
   "source": [
    "### regra de viabilidade para uma rota (dado ordem de atendimento)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4428e258",
   "metadata": {},
   "source": [
    "### penalizações (conforme Ren1000 e Prodist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c3c9c8",
   "metadata": {},
   "source": [
    "### GA para criar uma partição (atribuição) dos jobs entre veículos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b8b7ba",
   "metadata": {},
   "source": [
    "### GA main loop (moderado) + SA refinement on best individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb6faa8",
   "metadata": {},
   "source": [
    "### função principal que roda dia a dia (P1), obrigando atribuição de todos os jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c0c6d",
   "metadata": {},
   "source": [
    "### execução"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
