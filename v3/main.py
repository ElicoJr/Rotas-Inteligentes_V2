import sys
import os
import argparse
from pathlib import Path
from datetime import datetime
from typing import List

import pandas as pd

# permitir rodar de qualquer pasta
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from v3.data_loader import prepare_equipes_v3, prepare_pendencias_v3
from v2.optimization import MetaHeuristica


RESULTS_DIR = Path("results_v3")
RESULTS_DIR.mkdir(exist_ok=True)

# colunas mÃ­nimas que queremos garantir no resultado
REQUIRED_COLS = [
    "tipo_serv",
    "numos",
    "datasol",
    "dataven",
    "datater_trab",
    "TD",
    "TE",
    "equipe",
    "dthaps_ini",
    "dthaps_fim_ajustado",
    "inicio_turno",
    "fim_turno",
    "dthpausa_ini",
    "dthpausa_fim",
    "dth_chegada_estimada",
    "dth_final_estimada",
    "fim_turno_estimado",
    "eta_source",
    "base_lon",
    "base_lat",
    "chegada_base",
]


def log(msg: str) -> None:
    print(msg, flush=True)


def _ensure_result_schema(df: pd.DataFrame) -> pd.DataFrame:
    """Garante um layout estÃ¡vel para o V3.

    MantÃ©m todas as colunas do V2 e adiciona campos de pausa e chegada_base.
    """
    for c in REQUIRED_COLS:
        if c not in df.columns:
            df[c] = pd.NA

    # normalizar datas relevantes
    dt_cols = [
        "datasol",
        "dataven",
        "datater_trab",
        "dthaps_ini",
        "dthaps_fim_ajustado",
        "inicio_turno",
        "fim_turno",
        "dthpausa_ini",
        "dthpausa_fim",
        "dth_chegada_estimada",
        "dth_final_estimada",
        "fim_turno_estimado",
        "chegada_base",
    ]
    for c in dt_cols:
        if c in df.columns:
            df[c] = pd.to_datetime(df[c], errors="coerce")

    df["eta_source"] = df["eta_source"].astype("string")

    # garante ordem base, mantendo colunas extras ao final
    ordered = [c for c in REQUIRED_COLS if c in df.columns]
    extras = [c for c in df.columns if c not in ordered]
    return df[ordered + extras]


def simular_v3(
    df_eq: pd.DataFrame,
    df_te: pd.DataFrame,
    df_co: pd.DataFrame,
    limite_por_equipe: int = 15,
    debug: bool = False,
) -> None:
    """SimulaÃ§Ã£o V3 com regras:
    - Equipes comeÃ§am e terminam na base fixa.
    - Cada OS Ã© atribuÃ­da no mÃ¡ximo uma vez.
    - Pausa da equipe respeitada (sem deslocamento/serviÃ§o no intervalo).
    """

    # dias vindos do DT_REF das equipes
    dias = sorted(pd.to_datetime(df_eq["dt_ref"].dropna().unique()))
    if not dias:
        log("âš ï¸  Nenhum dia encontrado em Equipes.")
        return

    log(f"\nðŸ“† SimulaÃ§Ã£o V3 de {len(dias)} dias ({dias[0].date()} â†’ {dias[-1].date()})\n")

    # pools globais de pendÃªncias (podem ser multi-dia)
    pend_tec_global = df_te.copy()
    pend_com_global = df_co.copy()

    for i, dia in enumerate(dias, 1):
        log("=" * 120)
        log(f"ðŸ—“ï¸  Dia {i}/{len(dias)} â€” {dia.date()}")

        # equipes do dia
        eq_dia = df_eq[df_eq["dt_ref"] == dia].copy()
        log(f"ðŸ‘¥ Equipes no dia: {len(eq_dia)}")

        if eq_dia.empty:
            log("âš ï¸  Nenhuma equipe para este dia.")
            continue

        # pendÃªncias disponÃ­veis para o dia (antes de qualquer atribuiÃ§Ã£o)
        pend_tec_dia = pend_tec_global[pend_tec_global["dt_ref"] == dia].copy()
        pend_com_dia = pend_com_global[pend_com_global["dt_ref"] == dia].copy()

        atribs_dia: List[pd.DataFrame] = []

        for _, equipe_row in eq_dia.iterrows():
            nome_eq = equipe_row.get("nome", "N/D")

            # criar meta-heurÃ­stica com o snapshot atual de pendÃªncias do dia
            mh = MetaHeuristica(equipe_row, pend_tec_dia, pend_com_dia, limite_por_equipe)
            try:
                sol = mh.otimizar_para_equipe()
            except Exception as e:
                log(f"ðŸ’¥ Falha na equipe {nome_eq}: {e}")
                continue

            if not sol or not isinstance(sol.get("resp"), pd.DataFrame) or sol["resp"].empty:
                log(f"âš ï¸  {nome_eq}: Nenhuma OS atribuÃ­da")
                continue

            df_resp = sol["resp"].copy()
            # chegada_base == fim_turno_estimado
            if "fim_turno_estimado" in df_resp.columns:
                df_resp["chegada_base"] = df_resp["fim_turno_estimado"]

            df_resp = _ensure_result_schema(df_resp)
            log(f"ðŸšš Equipe {nome_eq} â†’ {len(df_resp)} serviÃ§os atribuÃ­dos")
            atribs_dia.append(df_resp)

            # remover OS atribuÃ­das dos pools (dia + global) para garantir exclusividade
            if "numos" in df_resp.columns:
                try:
                    atendidos = (
                        df_resp["numos"]
                        .dropna()
                        .astype("int64", errors="ignore")
                        .astype(str)
                        .unique()
                        .tolist()
                    )
                except Exception:
                    atendidos = []

                if atendidos:
                    # converter numos para string nas pendÃªncias para comparaÃ§Ã£o robusta
                    for dname, d in (
                        ("pend_tec_dia", pend_tec_dia),
                        ("pend_com_dia", pend_com_dia),
                        ("pend_tec_global", pend_tec_global),
                        ("pend_com_global", pend_com_global),
                    ):
                        if "numos" in d.columns:
                            mask = ~d["numos"].astype(str).isin(atendidos)
                            locals()[dname] = d[mask]

        if atribs_dia:
            out = _ensure_result_schema(pd.concat(atribs_dia, ignore_index=True))
            out_file = RESULTS_DIR / f"atribuicoes_{dia.date()}.parquet"
            out.to_parquet(out_file, index=False)
            log(f"ðŸ“Š {len(out)} registros salvos â†’ {out_file}")

            if debug:
                cols_chk = [
                    "dth_chegada_estimada",
                    "dth_final_estimada",
                    "fim_turno_estimado",
                    "chegada_base",
                ]
                log(
                    "   â€¢ "
                    + " | ".join(
                        [f"{c}: {out[c].notna().sum()} preenchidas" for c in cols_chk if c in out.columns]
                    )
                )
                if "eta_source" in out.columns:
                    log(f"   â€¢ eta_source: {dict(out['eta_source'].value_counts(dropna=False))}")
        else:
            log("âš ï¸ Nenhum registro atribuÃ­do neste dia.")


def main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument("--limite", type=int, default=15, help="Limite mÃ¡ximo de OS por equipe")
    parser.add_argument("--debug", action="store_true", help="Imprimir estatÃ­sticas adicionais")
    args = parser.parse_args()

    log("=" * 120)
    log(f"ðŸš€ SimulaÃ§Ã£o V3 iniciada Ã s {datetime.now():%H:%M:%S}")

    try:
        df_eq = prepare_equipes_v3()
        df_te, df_co = prepare_pendencias_v3()
    except Exception as e:
        log(f"ðŸ’¥ Erro ao carregar dataframes: {e}")
        raise

    simular_v3(df_eq, df_te, df_co, limite_por_equipe=args.limite, debug=args.debug)

    log("\nâœ… PROCESSO V3 FINALIZADO COM SUCESSO!")
    log(f"ðŸ“‚ Resultados em: {RESULTS_DIR.resolve()}")


if __name__ == "__main__":
    main()
